# MultiModalExtractor.py

import os
import json
import whisper
import easyocr
import ffmpeg
import numpy as np

# === åŠ è½½æ¨¡å‹ ===
print("ğŸ¯ æ­£åœ¨åŠ è½½æ¨¡å‹...")
whisper_model = whisper.load_model("base")
ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=False)
print("âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")

# === éŸ³é¢‘å¤„ç†å‡½æ•° ===
def transcribe_audio(audio_path: str):
    if not os.path.isfile(audio_path):
        return None, "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨"
    try:
        print(f"ğŸ§ æ­£åœ¨è§£ç éŸ³é¢‘: {audio_path}")
        process = (
            ffmpeg
            .input(audio_path, threads=0)
            .output('pipe:', format='f32le', ac=1, ar='16000')
            .run_async(pipe_stdout=True, pipe_stderr=True)
        )
        out, err = process.communicate()
        audio_np = np.frombuffer(out, np.float32)
        print("ğŸ¤– Whisper æ­£åœ¨è¯†åˆ«...")
        result = whisper_model.transcribe(audio_np, language='zh')
        text = result["text"].strip()
        print("âœ… è¯†åˆ«ç»“æœï¼š", text)
        return text, None
    except Exception as e:
        return None, f"éŸ³é¢‘è¯†åˆ«å¤±è´¥ï¼š{e}"

# === å›¾åƒå¤„ç†å‡½æ•° ===
def extract_image_text(image_path: str):
    if not os.path.isfile(image_path):
        return None, "å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨"
    try:
        print(f"ğŸ–¼ æ­£åœ¨è¯†åˆ«å›¾åƒ: {image_path}")
        result = ocr_reader.readtext(image_path, detail=0)
        text = '\n'.join(result).strip()
        print("âœ… å›¾åƒè¯†åˆ«ç»“æœï¼š", text)
        return text, None
    except Exception as e:
        return None, f"å›¾åƒè¯†åˆ«å¤±è´¥ï¼š{e}"
